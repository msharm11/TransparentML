{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classifiers import TransparentLogisticRegression\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from time import time\n",
    "from scipy.sparse.construct import diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imdb(path, shuffle = True, random_state=42, vectorizer = CountVectorizer(min_df=5, max_df=1.0, binary=True)):\n",
    "    \n",
    "    print \"Loading the imdb reviews data\"\n",
    "    \n",
    "    train_neg_files = glob.glob(path+\"\\\\train\\\\neg\\\\*.txt\")\n",
    "    train_pos_files = glob.glob(path+\"\\\\train\\\\pos\\\\*.txt\")\n",
    "    \n",
    "    train_corpus = []\n",
    "    \n",
    "    y_train = []\n",
    "    \n",
    "    for tnf in train_neg_files:\n",
    "        f = open(tnf, 'r')\n",
    "        line = f.read()\n",
    "        train_corpus.append(line)\n",
    "        y_train.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in train_pos_files:\n",
    "        f = open(tpf, 'r')\n",
    "        line = f.read()\n",
    "        train_corpus.append(line)\n",
    "        y_train.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    test_neg_files = glob.glob(path+\"\\\\test\\\\neg\\\\*.txt\")\n",
    "    test_pos_files = glob.glob(path+\"\\\\test\\\\pos\\\\*.txt\")\n",
    "    \n",
    "    test_corpus = []\n",
    "    \n",
    "    y_test = []\n",
    "    \n",
    "    for tnf in test_neg_files:\n",
    "        f = open(tnf, 'r')\n",
    "        test_corpus.append(f.read())\n",
    "        y_test.append(0)\n",
    "        f.close()\n",
    "    \n",
    "    for tpf in test_pos_files:\n",
    "        f = open(tpf, 'r')\n",
    "        test_corpus.append(f.read())\n",
    "        y_test.append(1)\n",
    "        f.close()\n",
    "        \n",
    "    print \"Data loaded.\"\n",
    "    \n",
    "    print \"Extracting features from the training dataset using a sparse vectorizer\"\n",
    "    print \"Feature extraction technique is %s.\" % vectorizer\n",
    "    t0 = time()\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(train_corpus)\n",
    "    \n",
    "    duration = time() - t0\n",
    "    print(\"done in %fs\" % (duration))\n",
    "    print \"n_samples: %d, n_features: %d\" % X_train.shape\n",
    "    print\n",
    "        \n",
    "    print \"Extracting features from the test dataset using the same vectorizer\"\n",
    "    t0 = time()\n",
    "        \n",
    "    X_test = vectorizer.transform(test_corpus)\n",
    "    \n",
    "    duration = time() - t0\n",
    "    print(\"done in %fs\" % (duration))\n",
    "    print \"n_samples: %d, n_features: %d\" % X_test.shape\n",
    "    print\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(y_train))        \n",
    "        \n",
    "        X_train = X_train.tocsr()\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        train_corpus_shuffled = [train_corpus[i] for i in indices]\n",
    "        \n",
    "        \n",
    "        indices = np.random.permutation(len(y_test))\n",
    "        \n",
    "        X_test = X_test.tocsr()\n",
    "        X_test = X_test[indices]\n",
    "        y_test = y_test[indices]\n",
    "        test_corpus_shuffled = [test_corpus[i] for i in indices]\n",
    "         \n",
    "    return X_train, y_train, X_test, y_test, train_corpus_shuffled, test_corpus_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "class ColoredDoc(object):\n",
    "    def __init__(self, doc, feature_names, coefs):\n",
    "        self.doc = doc\n",
    "        self.feature_names = feature_names\n",
    "        self.coefs = coefs\n",
    "        self.token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    def _repr_html_(self):\n",
    "        html_rep = \"\"\n",
    "        tokens = self.doc.split(\" \")        \n",
    "        for token in tokens:\n",
    "            vocab_tokens = self.token_pattern.findall(token.lower())\n",
    "            if len(vocab_tokens) > 0:\n",
    "                vocab_token = vocab_tokens[0]\n",
    "                try:\n",
    "                    vocab_index = self.feature_names.index(vocab_token)\n",
    "                    if self.coefs[vocab_index] > 0:\n",
    "                        html_rep = html_rep + \"<font color=blue> \" + token + \" </font>\"\n",
    "                    elif self.coefs[vocab_index] < 0:\n",
    "                        html_rep = html_rep + \"<font color=red> \" + token + \" </font>\"\n",
    "                    else:\n",
    "                        html_rep = html_rep + \"<font color=gray> \" + token + \" </font>\"\n",
    "                except:\n",
    "                    html_rep = html_rep + \"<font color=gray> \" + token + \" </font>\"\n",
    "            else:\n",
    "                html_rep = html_rep + \"<font color=gray> \" + token + \" </font>\"\n",
    "        return html_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n",
      "Loading the imdb reviews data\n",
      "Data loaded.\n",
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "Feature extraction technique is CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None).\n",
      "done in 5.672000s\n",
      "n_samples: 25000, n_features: 27272\n",
      "\n",
      "Extracting features from the test dataset using the same vectorizer\n",
      "done in 5.062000s\n",
      "n_samples: 25000, n_features: 27272\n",
      "\n",
      "\n",
      "Loading took 327.68s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Loading the data\"\n",
    "    \n",
    "t0 = time()\n",
    "\n",
    "vect = CountVectorizer(min_df=5, max_df=1.0, binary=True, ngram_range=(1, 1))\n",
    "X_train, y_train, X_test, y_test, train_corpus, test_corpus = load_imdb(\"C:\\\\Users\\\\mbilgic\\\\Desktop\\\\aclImdb\", shuffle=True, vectorizer=vect)\n",
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print\n",
    "print \"Loading took %0.2fs.\" % duration\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier\n",
      "\n",
      "Fitting took 0.53s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Fitting the classifier\"\n",
    "\n",
    "t0 = time()\n",
    "clf = TransparentLogisticRegression(penalty='l1', C=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print\n",
    "print \"Fitting took %0.2fs.\" % duration\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the evidences\n",
      "\n",
      "Predicting evidences took 0.10s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Predicting the evidences\"\n",
    "    \n",
    "t0 = time()\n",
    "neg_evi, pos_evi = clf.predict_evidences(X_test)\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print\n",
    "print \"Predicting evidences took %0.2fs.\" % duration\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the probs\n",
      "\n",
      "Predicting probs took 0.03s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Predicting the probs\"\n",
    "    \n",
    "t0 = time()\n",
    "probs = clf.predict_proba(X_test)\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print\n",
    "print \"Predicting probs took %0.2fs.\" % duration\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_evi = neg_evi + pos_evi\n",
    "\n",
    "evi_sorted = np.argsort(total_evi)\n",
    "\n",
    "coef_diags = diags(clf.coef_[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This was an excellent show. It came on PBS back home in Chicago and I remember Cindy Herron (From EnVogue) played the teen aged daughter. The show dealt with subjects such as sex, peer pressure and puberty. IT was about a middle class black family who had a teen aged daughter and son who moved to a middle class neighborhood from Oakland or somewhere (I can't remember). I remember several episodes but the one I remember most was when their cousin got her period for the first time. I was probably 7-8 when I first watched it and I was able to keep up with the program. This was a great show. I can't remember the name of the guy who played the son on the show, but I always got him confused with Kevin Hooks.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color=gray> This </font><font color=red> was </font><font color=gray> an </font><font color=blue> excellent </font><font color=gray> show. </font><font color=blue> It </font><font color=gray> came </font><font color=gray> on </font><font color=gray> PBS </font><font color=gray> back </font><font color=gray> home </font><font color=gray> in </font><font color=gray> Chicago </font><font color=blue> and </font><font color=gray> I </font><font color=gray> remember </font><font color=gray> Cindy </font><font color=gray> Herron </font><font color=gray> (From </font><font color=gray> EnVogue) </font><font color=gray> played </font><font color=gray> the </font><font color=gray> teen </font><font color=gray> aged </font><font color=gray> daughter. </font><font color=gray> The </font><font color=gray> show </font><font color=gray> dealt </font><font color=gray> with </font><font color=gray> subjects </font><font color=gray> such </font><font color=blue> as </font><font color=gray> sex, </font><font color=gray> peer </font><font color=gray> pressure </font><font color=blue> and </font><font color=gray> puberty. </font><font color=blue> IT </font><font color=red> was </font><font color=gray> about </font><font color=gray> a </font><font color=gray> middle </font><font color=gray> class </font><font color=gray> black </font><font color=blue> family </font><font color=blue> who </font><font color=gray> had </font><font color=gray> a </font><font color=gray> teen </font><font color=gray> aged </font><font color=gray> daughter </font><font color=blue> and </font><font color=gray> son </font><font color=blue> who </font><font color=gray> moved </font><font color=gray> to </font><font color=gray> a </font><font color=gray> middle </font><font color=gray> class </font><font color=gray> neighborhood </font><font color=gray> from </font><font color=gray> Oakland </font><font color=red> or </font><font color=gray> somewhere </font><font color=gray> (I </font><font color=gray> can't </font><font color=gray> remember). </font><font color=gray> I </font><font color=gray> remember </font><font color=gray> several </font><font color=gray> episodes </font><font color=gray> but </font><font color=gray> the </font><font color=gray> one </font><font color=gray> I </font><font color=gray> remember </font><font color=blue> most </font><font color=red> was </font><font color=blue> when </font><font color=gray> their </font><font color=gray> cousin </font><font color=gray> got </font><font color=gray> her </font><font color=gray> period </font><font color=gray> for </font><font color=gray> the </font><font color=blue> first </font><font color=blue> time. </font><font color=gray> I </font><font color=red> was </font><font color=gray> probably </font><font color=gray> 7-8 </font><font color=blue> when </font><font color=gray> I </font><font color=blue> first </font><font color=gray> watched </font><font color=blue> it </font><font color=blue> and </font><font color=gray> I </font><font color=red> was </font><font color=gray> able </font><font color=gray> to </font><font color=gray> keep </font><font color=gray> up </font><font color=gray> with </font><font color=gray> the </font><font color=gray> program. </font><font color=gray> This </font><font color=red> was </font><font color=gray> a </font><font color=blue> great </font><font color=gray> show. </font><font color=gray> I </font><font color=gray> can't </font><font color=gray> remember </font><font color=gray> the </font><font color=gray> name </font><font color=gray> of </font><font color=gray> the </font><font color=gray> guy </font><font color=blue> who </font><font color=gray> played </font><font color=gray> the </font><font color=gray> son </font><font color=gray> on </font><font color=gray> the </font><font color=gray> show, </font><font color=gray> but </font><font color=gray> I </font><font color=blue> always </font><font color=gray> got </font><font color=blue> him </font><font color=gray> confused </font><font color=gray> with </font><font color=gray> Kevin </font><font color=gray> Hooks. </font>"
      ],
      "text/plain": [
       "<__main__.ColoredDoc at 0x17c32b70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ColoredDoc(test_corpus[0], feature_names, clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
